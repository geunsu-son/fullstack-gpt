import streamlit as st
from openai import OpenAI
import time
import json
import os

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Research Assistant AI",
    page_icon="ğŸ”"
)

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.markdown("[ğŸ”— Git Repo Link](https://github.com/geunsu-son/fullstack-gpt)")
    openai_api_key = st.text_input("OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", type="password")

# ë©”ì¸ íƒ€ì´í‹€
st.title("Research Assistant AI")
st.write("""ì—°êµ¬í•˜ê³  ì‹¶ì€ ì£¼ì œë‚˜ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”. AIê°€ ê´€ë ¨ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³  ë¶„ì„í•˜ì—¬ ë‹µë³€í•´ë“œë¦½ë‹ˆë‹¤. ì´ AI ì–´ì‹œìŠ¤í„´íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.  
    - ì£¼ì œì— ëŒ€í•œ ì „ë¬¸ì ì¸ ë¶„ì„ ìˆ˜í–‰
    - ìˆ˜ì§‘í•œ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ í•œêµ­ì–´ë¡œ ë‹µë³€
    - ì—°êµ¬ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
    - ì €ì¥ëœ ì—°êµ¬ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¶”ê°€ ì§ˆë¬¸ ì‘ë‹µ
    """)

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” í•¨ìˆ˜ (ìºì‹±)
@st.cache_resource
def get_openai_client(api_key: str):
    return OpenAI(api_key=api_key)

# Assistant ì´ˆê¸°í™” í•¨ìˆ˜ (ìºì‹±)
@st.cache_resource
def get_or_create_assistant(_client):
    # ê¸°ì¡´ Assistant ëª©ë¡ í™•ì¸
    assistants = _client.beta.assistants.list(
        order="desc",
        limit=1
    )
    
    # ê¸°ì¡´ Research Assistantê°€ ìˆëŠ”ì§€ í™•ì¸
    for assistant in assistants.data:
        if assistant.name == "Research Assistant":
            return assistant
    
    # ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
    return _client.beta.assistants.create(
        name="Research Assistant",
        instructions="""ë‹¹ì‹ ì€ ë¦¬ì„œì¹˜ë¥¼ ìˆ˜í–‰í•˜ëŠ” í•œêµ­ì–´ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
        ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ë‹¤ìŒê³¼ ê°™ì´ ë‹µë³€í•´ì£¼ì„¸ìš”:

        ìƒˆë¡œìš´ ì—°êµ¬ ì£¼ì œì¸ ê²½ìš°:
        1. ì£¼ì–´ì§„ ì£¼ì œì— ëŒ€í•´ ì „ë¬¸ì ì¸ ë¶„ì„ ìˆ˜í–‰
        2. ìˆ˜ì§‘í•œ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ í•œêµ­ì–´ë¡œ ë‹µë³€
        3. ëª¨ë“  ì¡°ì‚¬ ë‚´ìš©ì„ txt íŒŒì¼ë¡œ ì €ì¥
        
        ì´ì „ ì—°êµ¬ ë‚´ìš©ì— ëŒ€í•œ ì¶”ê°€ ì§ˆë¬¸ì¸ ê²½ìš°:
        1. ì €ì¥ëœ ì—°êµ¬ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ë‹µë³€
        2. í•„ìš”í•œ ê²½ìš° ì¶”ê°€ ë¶„ì„ ìˆ˜í–‰
        3. ìƒˆë¡œìš´ í†µì°°ì´ë‚˜ ê´€ì  ì œì‹œ
        
        ë‹µë³€ì€ í•­ìƒ í•œêµ­ì–´ë¡œ í•´ì£¼ì‹œê³ , ì „ë¬¸ì ì´ê³  ê°ê´€ì ì¸ í†¤ì„ ìœ ì§€í•´ì£¼ì„¸ìš”.
        ìƒˆë¡œìš´ ì—°êµ¬ ê²°ê³¼ë¥¼ ì €ì¥í•  ë•ŒëŠ” íŒŒì¼ ì´ë¦„ê³¼ ì €ì¥ê²½ë¡œë¥¼ ì¶œë ¥í•´ì£¼ì„¸ìš”.""",
        model="gpt-4-turbo-preview",
        tools=[{
            "type": "function",
            "function": {
                "name": "save_research_to_text",
                "description": "ì—°êµ¬ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "content": {
                            "type": "string",
                            "description": "ì €ì¥í•  ì—°êµ¬ ë‚´ìš©"
                        },
                        "filename": {
                            "type": "string",
                            "description": "ì €ì¥í•  íŒŒì¼ ì´ë¦„ (í™•ì¥ì í¬í•¨)"
                        }
                    },
                    "required": ["content", "filename"]
                }
            }
        }, {
            "type": "function",
            "function": {
                "name": "get_research_content",
                "description": "ì €ì¥ëœ ì—°êµ¬ ë‚´ìš©ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "filename": {
                            "type": "string",
                            "description": "ë¶ˆëŸ¬ì˜¬ íŒŒì¼ ì´ë¦„ (í™•ì¥ì í¬í•¨)"
                        }
                    },
                    "required": ["filename"]
                }
            }
        }]
    )

# íŒŒì¼ ì €ì¥ í•¨ìˆ˜
def save_research_to_text(content: str, filename: str):
    if not filename.endswith('.txt'):
        filename += '.txt'
    
    # ì—°êµ¬ ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs('research_results', exist_ok=True)
    filepath = os.path.join('research_results', filename)
    
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(content)
    
    # ì„¸ì…˜ ìƒíƒœì— í˜„ì¬ ì—°êµ¬ íŒŒì¼ ì €ì¥
    st.session_state.current_research_file = filename
    return f"ì—°êµ¬ ê²°ê³¼ê°€ {filepath} íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."

# íŒŒì¼ ì½ê¸° í•¨ìˆ˜
def get_research_content(filename: str):
    if not filename.endswith('.txt'):
        filename += '.txt'
    
    filepath = os.path.join('research_results', filename)
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
        return content
    except FileNotFoundError:
        return f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filepath}"

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
if "current_research_file" not in st.session_state:
    st.session_state.current_research_file = None

# OpenAI API í‚¤ í™•ì¸
if not openai_api_key:
    st.warning("OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    st.stop()

# OpenAI í´ë¼ì´ì–¸íŠ¸ì™€ Assistant ì´ˆê¸°í™”
openai_client = get_openai_client(openai_api_key)
assistant = get_or_create_assistant(openai_client)

# í˜„ì¬ ì—°êµ¬ íŒŒì¼ í‘œì‹œ
if st.session_state.current_research_file:
    st.sidebar.write(f"í˜„ì¬ ì—°êµ¬ íŒŒì¼: {st.session_state.current_research_file}")

# ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ì—°êµ¬í•˜ê³  ì‹¶ì€ ì£¼ì œë‚˜ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Assistant ì‘ë‹µ ì²˜ë¦¬
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        status_placeholder = st.empty()
        
        try:
            # ìŠ¤ë ˆë“œ ìƒì„±
            thread = openai_client.beta.threads.create()
            
            # í˜„ì¬ ì—°êµ¬ íŒŒì¼ì´ ìˆë‹¤ë©´ ì»¨í…ìŠ¤íŠ¸ë¡œ ì¶”ê°€
            if st.session_state.current_research_file:
                research_content = get_research_content(st.session_state.current_research_file)
                context_message = f"""ì´ì „ ì—°êµ¬ ë‚´ìš©:
                {research_content}
                
                ì‚¬ìš©ì ì§ˆë¬¸:
                {prompt}"""
                openai_client.beta.threads.messages.create(
                    thread_id=thread.id,
                    role="user",
                    content=context_message
                )
            else:
                openai_client.beta.threads.messages.create(
                    thread_id=thread.id,
                    role="user",
                    content=prompt
                )
            
            # ì‹¤í–‰ ì‹œì‘
            run = openai_client.beta.threads.runs.create(
                thread_id=thread.id,
                assistant_id=assistant.id
            )
            
            # ì‹¤í–‰ ì™„ë£Œ ëŒ€ê¸°
            while run.status in ["queued", "in_progress"]:
                status_placeholder.text(f"ìƒíƒœ: {run.status}")
                run = openai_client.beta.threads.runs.retrieve(
                    thread_id=thread.id,
                    run_id=run.id
                )
                time.sleep(1)
            
            # ë„êµ¬ í˜¸ì¶œ ì²˜ë¦¬
            if run.status == "requires_action":
                tool_calls = run.required_action.submit_tool_outputs.tool_calls
                tool_outputs = []
                
                for tool_call in tool_calls:
                    args = json.loads(tool_call.function.arguments)
                    if tool_call.function.name == "save_research_to_text":
                        output = save_research_to_text(args["content"], args["filename"])
                        tool_outputs.append({
                            "tool_call_id": tool_call.id,
                            "output": output
                        })
                    elif tool_call.function.name == "get_research_content":
                        output = get_research_content(args["filename"])
                        tool_outputs.append({
                            "tool_call_id": tool_call.id,
                            "output": output
                        })
                
                # ë„êµ¬ ì¶œë ¥ ì œì¶œ
                run = openai_client.beta.threads.runs.submit_tool_outputs(
                    thread_id=thread.id,
                    run_id=run.id,
                    tool_outputs=tool_outputs
                )
                
                # ì‹¤í–‰ ì™„ë£Œ ëŒ€ê¸°
                while run.status in ["queued", "in_progress"]:
                    status_placeholder.text(f"ìƒíƒœ: {run.status}")
                    run = openai_client.beta.threads.runs.retrieve(
                        thread_id=thread.id,
                        run_id=run.id
                    )
                    time.sleep(1)
            
            # ì‘ë‹µ ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°
            messages = openai_client.beta.threads.messages.list(thread_id=thread.id)
            
            # ìµœì‹  assistant ë©”ì‹œì§€ í‘œì‹œ
            for message in messages.data:
                if message.role == "assistant":
                    full_response = message.content[0].text.value
                    break
            
            message_placeholder.markdown(full_response)
            st.session_state.messages.append({"role": "assistant", "content": full_response})
            
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        finally:
            status_placeholder.empty()

# ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” ë²„íŠ¼
if st.sidebar.button("ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"):
    st.session_state.messages = []
    st.session_state.current_research_file = None
    st.experimental_rerun() 